# IRIS v6.0 - Model Configuration Guide

## üìã √ñversikt

IRIS v6.0 har ett kraftfullt och flexibelt system f√∂r att hantera AI-modeller. Systemet g√∂r det enkelt att:
- Konfigurera och hantera flera AI-modeller
- V√§lja r√§tt modell f√∂r olika anv√§ndningsfall
- Automatiskt anv√§nda fallback-modeller
- Filtrera modeller baserat p√• behov

## üóÇÔ∏è Filer

### Konfigurationsfiler
- `config/models.yaml` - Centraliserad modellkonfiguration
- `src/core/model_config.py` - Model Configuration Manager
- `src/utils/model_manager_cli.py` - CLI-verktyg f√∂r modellhantering

## üöÄ Snabbstart

### 1. Lista tillg√§ngliga modeller

```bash
python -m src.utils.model_manager_cli list
```

### 2. Visa information om en modell

```bash
python -m src.utils.model_manager_cli info kimi-k2
```

### 3. Visa modeller f√∂r en profil

```bash
python -m src.utils.model_manager_cli profile snabb
```

### 4. Lista alla anv√§ndningsfall

```bash
python -m src.utils.model_manager_cli usecases
```

## üìñ Anv√§ndning i kod

### H√§mta Model Config Manager

```python
from src.core.model_config import get_model_config_manager

manager = get_model_config_manager()
```

### H√§mta modellkonfiguration

```python
# H√§mta modell via nyckel
model = manager.get_model("kimi-k2")
print(f"Modell: {model.namn}")
print(f"Provider: {model.provider}")
print(f"Max tokens: {model.max_tokens}")

# H√§mta modell via model_id
model = manager.get_model_by_id("moonshotai/kimi-k2-instruct-0905")
```

### H√§mta modeller f√∂r en profil

```python
# H√§mta prim√§r modell f√∂r profil
primary_model = manager.get_model_for_profile("snabb")
print(f"Prim√§r modell f√∂r 'snabb': {primary_model}")

# H√§mta fallback-modeller
fallbacks = manager.get_fallback_models("snabb")
print(f"Fallback-modeller: {fallbacks}")
```

### Filtrera modeller

```python
# H√§mta alla Groq-modeller
groq_models = manager.get_models_by_provider("groq")

# Filtrera med flera kriterier
filtered = manager.filter_models(
    provider="groq",
    streaming=True,
    max_kostnad="l√•g"
)
```

### Anv√§nd med Settings

```python
from src.core.config import get_settings

settings = get_settings()
manager = settings.get_model_config_manager()

# H√§mta modell-ID f√∂r en profil
model_id = settings.get_model_for_profile("smart")
print(f"Modell f√∂r 'smart': {model_id}")
```

## üõ†Ô∏è L√§gga till nya modeller

Redigera `config/models.yaml`:

```yaml
ai_models:
  din-nya-modell:
    namn: "Din Nya Modell"
    provider: "groq"  # eller xai, lokal
    model_id: "provider-model-id"
    beskrivning: "Beskrivning av modellen"
    max_tokens: 8192
    default_temperature: 0.7
    supports_streaming: true
    hastighet: "snabb"  # extremt snabb, mycket snabb, snabb, medel
    kostnad: "l√•g"  # gratis, l√•g, medel, h√∂g
    rekommenderad_f√∂r:
      - "anv√§ndningsfall 1"
      - "anv√§ndningsfall 2"
    privat: false  # true f√∂r lokal modell
    supports_vision: false  # true f√∂r multimodal
```

## üìä Modellattribut

### Hastighet
- **extremt snabb**: < 1 sekund
- **mycket snabb**: 1-2 sekunder
- **snabb**: 2-5 sekunder
- **medel**: 5-10 sekunder

### Kostnad
- **gratis**: Ingen kostnad (lokal)
- **l√•g**: Billig API-anv√§ndning
- **medel**: Normal API-kostnad
- **h√∂g**: Dyrare API-anv√§ndning

## üéØ Anv√§ndningsfall

### Snabba svar
Rekommenderade modeller:
- `llama-3-8b` - Extremt snabb
- `kimi-k2` - Mycket snabb

### Komplexa analyser
Rekommenderade modeller:
- `llama-3-70b` - Kraftfull
- `grok-beta` - Avancerad
- `mixtral-8x7b` - Stor kontext

### Dokumentanalys
Rekommenderade modeller:
- `mixtral-8x7b` - 32K kontext
- `llama-3-70b` - H√∂g kvalitet

### Privat/K√§nslig data
Rekommenderade modeller:
- `lokal` - 100% privat

## üîÑ Fallback-strategi

Systemet anv√§nder automatisk fallback vid fel:

```
Profil "snabb":
  Prim√§r ‚Üí kimi-k2
  Alternativ ‚Üí llama-3-8b, llama-3-70b
  Fallback ‚Üí lokal

Profil "smart":
  Prim√§r ‚Üí kimi-k2
  Alternativ ‚Üí llama-3-70b, grok-beta, mixtral-8x7b
  Fallback ‚Üí lokal

Profil "privat":
  Prim√§r ‚Üí lokal
  Alternativ ‚Üí (ingen)
  Fallback ‚Üí lokal
```

## üß™ Testning

### Test model configuration

```python
import pytest
from src.core.model_config import get_model_config_manager

def test_model_loading():
    manager = get_model_config_manager()
    assert len(manager.models) > 0

def test_get_model():
    manager = get_model_config_manager()
    model = manager.get_model("kimi-k2")
    assert model is not None
    assert model.provider == "groq"

def test_profile_mapping():
    manager = get_model_config_manager()
    primary = manager.get_model_for_profile("snabb")
    assert primary == "kimi-k2"
```

## üìù Best Practices

1. **Anv√§nd r√§tt modell f√∂r r√§tt uppgift**
   - Snabba svar ‚Üí Anv√§nd l√§tta modeller (llama-3-8b)
   - Komplexa analyser ‚Üí Anv√§nd kraftfulla modeller (llama-3-70b)
   - Privat data ‚Üí Anv√§nd lokal modell

2. **Konfigurera fallbacks**
   - Alltid ha minst en fallback-modell
   - Lokal modell som sista fallback

3. **Optimera f√∂r kostnad**
   - Anv√§nd filter f√∂r att v√§lja kostnadseffektiva modeller
   - Testa med billigare modeller f√∂rst

4. **Dokumentera anv√§ndningsfall**
   - L√§gg till nya anv√§ndningsfall i `models.yaml`
   - Specificera rekommenderade modeller

## üîß Fels√∂kning

### Modell hittas inte
```python
model = manager.get_model("fel-nyckel")
if model is None:
    print("Modellen finns inte!")
    # Lista tillg√§ngliga modeller
    print(manager.list_all_models())
```

### Provider inte tillg√§nglig
```python
from src.services.ai_providers.factory import AIProviderFactory

settings = get_settings()
available = AIProviderFactory.get_available_providers(settings)
print(f"Tillg√§ngliga providers: {available}")
```

### Ladda om konfiguration
```python
# Om du √§ndrar models.yaml under k√∂rning
from src.core.model_config import ModelConfigManager

# Skapa ny instance (ej cache)
manager = ModelConfigManager()
```

## üé® Exempel: V√§lj modell dynamiskt

```python
from src.core.model_config import get_model_config_manager

def v√§lj_modell_f√∂r_uppgift(uppgift_typ: str, max_kostnad: str = "medel"):
    """V√§lj b√§sta modellen f√∂r en uppgift"""
    manager = get_model_config_manager()
    
    # F√• rekommendationer f√∂r anv√§ndningsfall
    rekommenderade = manager.get_recommended_models(uppgift_typ)
    
    if not rekommenderade:
        return "lokal"  # Fallback
    
    # Filtrera p√• kostnad
    for model_key in rekommenderade:
        model = manager.get_model(model_key)
        if model and model.kostnad in ["gratis", "l√•g", max_kostnad]:
            return model_key
    
    return rekommenderade[0]  # F√∂rsta rekommendationen

# Anv√§ndning
modell = v√§lj_modell_f√∂r_uppgift("snabba_svar", max_kostnad="l√•g")
print(f"Vald modell: {modell}")
```

## üìö API-referens

### ModelConfig (dataclass)
```python
@dataclass
class ModelConfig:
    namn: str
    provider: str
    model_id: str
    beskrivning: str
    max_tokens: int
    default_temperature: float
    supports_streaming: bool
    hastighet: str
    kostnad: str
    rekommenderad_f√∂r: List[str]
    privat: bool = False
    supports_vision: bool = False
```

### ModelConfigManager

#### Metoder

- `get_model(model_key: str) -> Optional[ModelConfig]`
- `get_model_by_id(model_id: str) -> Optional[ModelConfig]`
- `get_models_by_provider(provider: str) -> List[ModelConfig]`
- `get_model_for_profile(profile_name: str) -> Optional[str]`
- `get_fallback_models(profile_name: str) -> List[str]`
- `get_recommended_models(anv√§ndningsfall: str) -> List[str]`
- `list_all_models() -> Dict[str, str]`
- `get_model_info(model_key: str) -> Dict[str, Any]`
- `filter_models(...) -> List[str]`

## ‚úÖ F√∂rdelar med systemet

1. **Centraliserad konfiguration** - Alla modeller p√• ett st√§lle
2. **Enkel hantering** - CLI-verktyg och API
3. **Flexibel filtrering** - Hitta r√§tt modell f√∂r behov
4. **Automatisk fallback** - Robust felhantering
5. **Utbyggbart** - L√§tt att l√§gga till nya modeller
6. **Type-safe** - Dataclasses och type hints
7. **Cached** - Effektiv prestanda

---

**üéØ Nu √§r det enkelt att hantera och konfigurera AI-modeller i IRIS!**
