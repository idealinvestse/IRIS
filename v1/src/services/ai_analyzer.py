"""
IRIS v6.0 - AI Analyzer (Uppdaterad med Multi-Provider Support)
St√∂djer Groq Cloud (Kimi K2), xAI Grok och lokal AI
"""

import logging
from typing import Dict, Any, Optional
from src.services.ai_providers.factory import AIProviderFactory
from src.services.ai_providers.base import BaseAIProvider

logger = logging.getLogger(__name__)

class AIAnalyzer:
    """
    AI-analys med multi-provider support
    Automatisk fallback: Groq ‚Üí xAI ‚Üí Lokal
    """
    
    def __init__(self):
        from src.core.config import get_settings
        self.settings = get_settings()
        self.provider_cache: Dict[str, Optional[BaseAIProvider]] = {}
        logger.info("üß† AIAnalyzer initialiserad (multi-provider mode)")
    
    async def analyze(
        self,
        query: str,
        context_data: Dict[str, Any],
        profile: str,
        profile_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Analysera fr√•ga med vald AI-provider
        
        Args:
            query: Anv√§ndarfr√•ga
            context_data: Data fr√•n svenska k√§llor
            profile: Profil-namn (snabb, smart, privat)
            profile_config: Profil-konfiguration
            
        Returns:
            Dict med AI-analys
        """
        # H√§mta provider-specifik konfiguration
        provider_name = profile_config.get("ai_provider", "lokal")
        model = profile_config.get("ai_model", "lokal")
        temperature = profile_config.get("temperature", 0.7)
        max_tokens = profile_config.get("max_tokens", 2048)
        streaming = profile_config.get("streaming", False)
        
        logger.info(f"ü§ñ Analyserar med provider: {provider_name}, modell: {model}, streaming: {streaming}")
        
        # H√§mta eller skapa provider
        provider = self._get_provider(provider_name)
        
        if not provider:
            logger.warning(f"‚ö†Ô∏è Provider {provider_name} inte tillg√§nglig, f√∂rs√∂ker fallback")
            provider = self._get_fallback_provider(provider_name)
        
        # Bygg kontext fr√•n datak√§llor
        context = self._build_context(context_data)
        
        try:
            # Analysera med vald provider
            result = await provider.analyze(
                query=query,
                context=context,
                model=model,
                temperature=temperature,
                max_tokens=max_tokens,
                stream=streaming
            )
            
            logger.info(f"‚úÖ Analys slutf√∂rd med {provider.get_provider_name()}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Provider {provider_name} misslyckades: {e}", exc_info=True)
            
            # F√∂rs√∂k fallback
            return await self._try_fallback_providers(
                query, context, provider_name, model, temperature, max_tokens
            )
    
    def _get_provider(self, provider_name: str) -> Optional[BaseAIProvider]:
        """
        H√§mta eller skapa provider (cached)
        
        Args:
            provider_name: Namnet p√• providern
            
        Returns:
            Provider instance eller None
        """
        if provider_name not in self.provider_cache:
            self.provider_cache[provider_name] = AIProviderFactory.create_provider(
                provider_name, self.settings
            )
        
        return self.provider_cache[provider_name]
    
    def _get_fallback_provider(self, failed_provider: str) -> BaseAIProvider:
        """
        H√§mta fallback-provider n√§r prim√§r provider misslyckas
        
        Fallback-ordning: groq ‚Üí xai ‚Üí lokal
        
        Args:
            failed_provider: Namnet p√• providern som misslyckades
            
        Returns:
            Fallback provider (lokal som sista utv√§g)
        """
        fallback_order = ["groq", "xai", "lokal"]
        
        # Ta bort den som misslyckades
        if failed_provider in fallback_order:
            fallback_order.remove(failed_provider)
        
        # F√∂rs√∂k providers i ordning
        for provider_name in fallback_order:
            provider = self._get_provider(provider_name)
            if provider:
                logger.info(f"üîÑ Anv√§nder fallback provider: {provider_name}")
                return provider
        
        # Lokal √§r alltid tillg√§nglig som sista utv√§g
        logger.warning("‚ö†Ô∏è Anv√§nder lokal provider som sista fallback")
        local_provider = self._get_provider("lokal")
        if not local_provider:
            # Om till och med lokal misslyckas, skapa en ny instans
            from src.services.ai_providers.factory import AIProviderFactory
            local_provider = AIProviderFactory.create_provider("lokal", self.settings)
            if local_provider:
                self.provider_cache["lokal"] = local_provider
        return local_provider
    
    async def _try_fallback_providers(
        self,
        query: str,
        context: str,
        failed_provider: str,
        model: str,
        temperature: float,
        max_tokens: int
    ) -> Dict[str, Any]:
        """
        F√∂rs√∂k med fallback-providers
        """
        fallback_order = ["xai", "lokal"] if failed_provider == "groq" else ["lokal"]
        
        for fallback_name in fallback_order:
            try:
                logger.info(f"üîÑ F√∂rs√∂ker fallback: {fallback_name}")
                fallback_provider = self._get_provider(fallback_name)
                
                if fallback_provider:
                    # Anv√§nd justerad temperatur f√∂r fallback
                    # Minska n√•got f√∂r mer stabila svar i fallback
                    adjusted_temperature = max(0.1, temperature * 0.8) if temperature > 0 else 0.5
                    
                    result = await fallback_provider.analyze(
                        query=query,
                        context=context,
                        model="lokal" if fallback_name == "lokal" else model,
                        temperature=adjusted_temperature,
                        max_tokens=max_tokens,
                        stream=False
                    )
                    
                    logger.info(f"‚úÖ Fallback {fallback_name} lyckades")
                    return result
                    
            except Exception as fallback_error:
                logger.error(f"‚ùå Fallback {fallback_name} misslyckades: {fallback_error}")
                continue
        
        # Om allt misslyckas, returnera fel-meddelande
        return self._error_response(query, Exception("Alla AI-providers misslyckades"))
    
    def _build_context(self, context_data: Dict[str, Any]) -> str:
        """
        Bygg kontext-str√§ng fr√•n samlad data
        
        Args:
            context_data: Data fr√•n svenska k√§llor
            
        Returns:
            Formaterad kontext-str√§ng
        """
        context_parts = []
        
        for source, data in context_data.items():
            if isinstance(data, dict) and not data.get("error") and data.get("available"):
                context_parts.append(f"\n=== {source.upper()} ===")
                
                # Formatera data baserat p√• k√§lla
                if source == "omx":
                    if "price" in data:
                        context_parts.append(f"OMX Index: {data['price']} SEK")
                        if "change" in data:
                            context_parts.append(f"F√∂r√§ndring: {data['change']}")
                
                elif source == "scb":
                    if "summary" in data:
                        context_parts.append(data["summary"])
                    if "data" in data:
                        for key, value in data["data"].items():
                            context_parts.append(f"{key}: {value}")
                
                elif source == "svenska_nyheter":
                    if "headlines" in data:
                        context_parts.append("Senaste nyheterna:")
                        for headline in data["headlines"][:3]:
                            context_parts.append(f"- {headline}")
                
                elif source == "smhi":
                    if "forecast" in data:
                        context_parts.append(f"V√§der: {data['forecast']}")
                    if "temperature" in data:
                        context_parts.append(f"Temperatur: {data['temperature']}¬∞C")
                
                # Generisk data-representation
                elif "summary" in data:
                    context_parts.append(str(data["summary"]))
        
        if context_parts:
            return "\n".join(context_parts)
        else:
            return "Ingen kontextdata tillg√§nglig fr√•n k√§llor."
    
    def _error_response(self, query: str, error: Exception) -> Dict[str, Any]:
        """
        Generera fel-respons
        
        Args:
            query: Ursprunglig fr√•ga
            error: Exception som orsakade felet
            
        Returns:
            Fel-respons dict
        """
        return {
            "svar": f"Kunde inte analysera fr√•gan '{query}' p√• grund av tekniska problem. Alla AI-providers √§r tillf√§lligt otillg√§ngliga.",
            "modell": "error",
            "provider": "none",
            "typ": "error",
            "tokens_used": 0,
            "error": str(error),
            "rekommendation": "F√∂rs√∂k igen senare eller kontakta support om problemet kvarst√•r."
        }
    
    def get_available_providers(self) -> list:
        """
        H√§mta lista √∂ver tillg√§ngliga providers
        
        Returns:
            List av provider-namn
        """
        return AIProviderFactory.get_available_providers(self.settings)
